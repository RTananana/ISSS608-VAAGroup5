---
title: "test code"
---

```{r}
pacman:::p_load(jsonlite, tidygraph, ggraph, visNetwork, graphlayouts
                , ggforce, tidytext, tidyverse, ggplot2, plotly, skimr
                , DT, igraph, scales, viridis, colorspace, stringr
                , knitr, wordcloud, bslib, thematic, shiny, colourpicker
                , devtools, wordcloud2, tm)

mc3 <-fromJSON("data/MC3.json")

inputdata <- mc3_nodes %>%
      select(product_services)

mc3_nodes <- as_tibble(mc3$nodes) %>%
  distinct() %>%
  mutate(country = as.character(country),
         id = as.character(id),
         product_services = as.character(product_services),
         revenue_omu = as.numeric(as.character(revenue_omu)),
         type = as.character(type)) %>%
  select (id, country, type, revenue_omu, product_services)

token_nodes <- mc3_nodes %>%
      unnest_tokens(word,
                    product_services) 


token_nodes <- mc3_nodes %>%
      unnest_tokens(word, 
                    product_services)
                        


token_nodes2 <- mc3_nodes %>%
      unnest_tokens(
        input = product_services, 
        output = bigram, 
        token = 'ngrams', 
        n = 2) %>%
      filter(! is.na(bigram))

new_stop_words_bi <- stop_words %>% 
  add_row(word=NA,lexicon="SMART") %>%
  add_row(word="related",lexicon="SMART") %>%
  add_row(word="including",lexicon="SMART") %>%
  add_row(word="wide",lexicon="SMART") %>%
  add_row(word="range",lexicon="SMART") %>%
  add_row(word="freelance",lexicon="SMART") %>%
  add_row(word="researcher",lexicon="SMART") %>%
  add_row(word="products",lexicon="SMART") %>%
  add_row(word="processing",lexicon="SMART") %>%
  add_row(word="preparations",lexicon="SMART") %>%
  add_row(word="food",lexicon="SMART") %>%
  add_row(word="items",lexicon="SMART") %>%
  add_row(word="character",lexicon="SMART") %>%
  add_row(word="0",lexicon="SMART") %>%
  add_row(word="unknown",lexicon="SMART") %>%
  add_row(word="services",lexicon="SMART")
    
data <- token_nodes2 %>%  
      separate(col = bigram, into = c('word1', 'word2'), sep = ' ') %>% 
      filter(! word1 %in% new_stop_words_bi$word) %>% 
      filter(! word2 %in% new_stop_words_bi$word) %>% 
      filter(! is.na(word1)) %>% 
      filter(! is.na(word2))%>% 
      select(word1, word2) %>%
      unite(bigram, word1, word2, sep = " ")

token_nodes2 %>%  
  separate(col = bigram, into = c('word1', 'word2'), sep = ' ') %>% 
  filter(! word1 %in% new_stop_words_bi$word) %>% 
  filter(! word2 %in% new_stop_words_bi$word) %>% 
  filter(! is.na(word1)) %>% 
  filter(! is.na(word2))%>% 
  select(word1, word2) %>%
  count(word1, word2, sort = TRUE) %>% 
  # We rename the weight column so that the 
  # associated network gets the weights (see below).
  rename(weight = n)


create_datatable <- function(data) {
    
    # If text is provided, convert it to a dataframe of word frequencies
    if (is.character(data)) {
      corpus <- Corpus(VectorSource(data))
      corpus <- tm_map(corpus, tolower)
      corpus <- tm_map(corpus, removePunctuation)
      corpus <- tm_map(corpus, removeNumbers)
      corpus <- tm_map(corpus, stripWhitespace)
      corpus <- tm_map(corpus, removeWords, stopwords(tolower("English")))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_1))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_2))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_3))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_4))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_5))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_6))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_7))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_8))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_9))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_10))
      dfm <- dfm(corpus, ngrams = 2)
      tdm <- as.matrix(dfm)
      data <- sort(rowSums(tdm), decreasing = TRUE)
      data <- data.table(word = names(word1, word2), freq = as.numeric(data))
    }
  
  data <- head(data, n = num_words)
    if (nrow(data) == 0) {
      return(NULL)
    }
  
  datatable(data)
  
  }

home <- create_datatable(data)
  




create_datatable <- function(data) {
    if (is.character(data)) {
      corpus <- Corpus(VectorSource(data))
      corpus <- tm_map(corpus, tolower)
      corpus <- tm_map(corpus, removePunctuation)
      corpus <- tm_map(corpus, removeNumbers)
      corpus <- tm_map(corpus, stripWhitespace)
      corpus <- tm_map(corpus, removeWords, stopwords(tolower("English")))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_1))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_2))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_3))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_4))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_5))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_6))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_7))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_8))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_9))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_10))
      dfm <- dfm(corpus, ngrams = 2)
      tdm <- as.matrix(dfm)
      data <- sort(rowSums(tdm), decreasing = TRUE)
      data <- data.frame(word = names(data), freq = as.numeric(data))
      
    }

    data <- data %>%
      separate(col = bigram, into = c('word1', 'word2'), sep = ' ') %>%
      count(word1, word2, sort = TRUE) %>%
      # We rename the weight column so that the 
      # associated network gets the weights (see below).
      rename(weight = n)
  }

```
