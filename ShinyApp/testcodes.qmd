---
title: "test code"
---

```{r}
pacman:::p_load(jsonlite, tidygraph, ggraph, visNetwork, graphlayouts
                , ggforce, tidytext, tidyverse, ggplot2, plotly, skimr
                , DT, igraph, scales, viridis, colorspace, stringr
                , knitr, wordcloud, bslib, thematic, shiny, colourpicker
                , devtools, wordcloud2, tm, data.table)

mc3 <-fromJSON("data/MC3.json")

inputdata <- mc3_nodes %>%
      select(product_services)

mc3_nodes <- as_tibble(mc3$nodes) %>%
  distinct() %>%
  mutate(country = as.character(country),
         id = as.character(id),
         product_services = as.character(product_services),
         revenue_omu = as.numeric(as.character(revenue_omu)),
         type = as.character(type)) %>%
  select (id, country, type, revenue_omu, product_services)

token_nodes <- mc3_nodes %>%
      unnest_tokens(word,
                    product_services) 


token_nodes <- mc3_nodes %>%
      unnest_tokens(word, 
                    product_services)
                        


token_nodes2 <- mc3_nodes %>%
      unnest_tokens(
        input = product_services, 
        output = bigram, 
        token = 'ngrams', 
        n = 2) %>%
      filter(! is.na(bigram))

new_stop_words_bi <- stop_words %>% 
  add_row(word=NA,lexicon="SMART") %>%
  add_row(word="related",lexicon="SMART") %>%
  add_row(word="including",lexicon="SMART") %>%
  add_row(word="wide",lexicon="SMART") %>%
  add_row(word="range",lexicon="SMART") %>%
  add_row(word="freelance",lexicon="SMART") %>%
  add_row(word="researcher",lexicon="SMART") %>%
  add_row(word="products",lexicon="SMART") %>%
  add_row(word="processing",lexicon="SMART") %>%
  add_row(word="preparations",lexicon="SMART") %>%
  add_row(word="food",lexicon="SMART") %>%
  add_row(word="items",lexicon="SMART") %>%
  add_row(word="character",lexicon="SMART") %>%
  add_row(word="0",lexicon="SMART") %>%
  add_row(word="unknown",lexicon="SMART") %>%
  add_row(word="services",lexicon="SMART")
    
data <- token_nodes2 %>%  
      separate(col = bigram, into = c('word1', 'word2'), sep = ' ') %>% 
      filter(! word1 %in% new_stop_words_bi$word) %>% 
      filter(! word2 %in% new_stop_words_bi$word) %>% 
      filter(! is.na(word1)) %>% 
      filter(! is.na(word2))%>% 
      select(word1, word2) 

token_nodes2 %>%  
  separate(col = bigram, into = c('word1', 'word2'), sep = ' ') %>% 
  filter(! word1 %in% new_stop_words_bi$word) %>% 
  filter(! word2 %in% new_stop_words_bi$word) %>% 
  filter(! is.na(word1)) %>% 
  filter(! is.na(word2))%>% 
  select(word1, word2) %>%
  count(word1, word2, sort = TRUE) %>% 
  # We rename the weight column so that the 
  # associated network gets the weights (see below).
  rename(weight = n)


create_datatable <- function(data) {
    
    # If text is provided, convert it to a dataframe of word frequencies
    if (is.character(data)) {
      corpus <- Corpus(VectorSource(data))
      corpus <- tm_map(corpus, tolower)
      corpus <- tm_map(corpus, removePunctuation)
      corpus <- tm_map(corpus, removeNumbers)
      corpus <- tm_map(corpus, stripWhitespace)
      corpus <- tm_map(corpus, removeWords, stopwords(tolower("English")))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_1))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_2))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_3))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_4))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_5))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_6))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_7))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_8))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_9))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_10))
      dfm <- dfm(corpus, ngrams = 2)
      tdm <- as.matrix(dfm)
      data <- sort(rowSums(tdm), decreasing = TRUE)
      data <- data.table(word = names(word1, word2), freq = as.numeric(data))
    }
  
  data <- head(data, n = num_words)
    if (nrow(data) == 0) {
      return(NULL)
    }
  
  datatable(data)
  
  }

home <- create_datatable(data)
  




create_datatable <- function(data) {
    if (is.character(data)) {
      corpus <- Corpus(VectorSource(data))
      corpus <- tm_map(corpus, tolower)
      corpus <- tm_map(corpus, removePunctuation)
      corpus <- tm_map(corpus, removeNumbers)
      corpus <- tm_map(corpus, stripWhitespace)
      corpus <- tm_map(corpus, removeWords, stopwords(tolower("English")))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_1))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_2))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_3))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_4))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_5))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_6))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_7))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_8))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_9))
      corpus <- tm_map(corpus, removeWords, c(input$words_to_remove_bi_10))
      dfm <- dfm(corpus, ngrams = 2)
      tdm <- as.matrix(dfm)
      data <- sort(rowSums(tdm), decreasing = TRUE)
      data <- data.frame(word = names(data), freq = as.numeric(data))
      
    }

    data <- data %>%
      separate(col = bigram, into = c('word1', 'word2'), sep = ' ') %>%
      count(word1, word2, sort = TRUE) %>%
      # We rename the weight column so that the 
      # associated network gets the weights (see below).
      rename(weight = n)
  }


create_datatable <- function(data) {
    if (is.character(data$word1) & is.character(data$word2)) {
      data <- data %>% 
        filter(! word1 %in% "frozen") %>% 
        filter(! word2 %in% "frozen")
      
    }

    data <- data %>%
      count(word1, word2, sort = TRUE) %>%
      # We rename the weight column so that the 
      # associated network gets the weights (see below).
      rename(weight = n)
    
    return(data)
  }


create_datatable(data)

bi.gram.count <- create_datatable(data)

str(bi.gram.count) 
bi.gram.count <- as.matrix(bi.gram.count)
threshold <- 3

bi.gram.count %>%
      mutate(weight = log(weight + 1))%>%
      filter(weight > threshold) %>%
      graph_from_data_frame(directed = FALSE)


network <- reactive({
    
    bi.gram.count <- create_datatable(bigram())
    
    bi.gram.count <- bi.gram.count %>% 
      filter(weight > input$threshold) %>%
      graph_from_data_frame(directed = FALSE)
    
    V(bi.gram.count)$cluster <- clusters(graph = bi.gram.count)$membership
    
    cc.bi.gram.count <- induced_subgraph(
      graph = bi.gram.count,
      vids = which(V(bi.gram.count)$cluster == which.max(clusters(graph = bi.gram.count)$csize))
      )
  
    V(cc.bi.gram.count)$degree <- strength(graph = cc.bi.gram.count)
    E(cc.bi.gram.count)$width <- E(cc.bi.gram.count)$weight/max(E(cc.bi.gram.count)$weight)
  
  
    network.D3 <- igraph_to_networkD3(g = cc.bi.gram.count)
    network.D3$nodes <- network.D3$nodes %>%
      mutate(Degree = (1E-2)*V(cc.bi.gram.count)$degree) %>%   
      mutate(Group = 1)
  
    network.D3$links$Width <- 8*E(cc.bi.gram.count)$width
  
    forceNetwork(
      Links = network.D3$links, 
      Nodes = network.D3$nodes, 
      Source = 'source', 
      Target = 'target',
      NodeID = 'name',
      Group = 'Group', 
      opacity = input$opacity,
      Value = 'Width',
      Nodesize = 'Degree', 
      # We input a JavaScript function.
      linkWidth = JS("function(d) { return Math.sqrt(d.value); }"), 
      fontSize = 12,
      zoom = TRUE, 
      opacityNoHover = 1
    )
  })
  
```
